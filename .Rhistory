dat <- as.data.frame(dat)
# Convert appropriate variables to numeric
factor.variables <- c("date","time")
# Convert variables to numeric, then normalise between 0 and 1 so that all time series are on the same plane
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.character)
# filter dataset for Coin prefix and all the midprice suffixes
coin.specific.variables <- grep(coin, colnames(input.data))
coin.pairs <- grep("midprice", colnames(input.data))
if (use.bids.as.predictor == FALSE){
col.selection <- unique(c(coin.specific.variables, coin.pairs))
} else {
col.selection <- unique(c(coin.specific.variables, coin.pairs))
col.2 <- intersect(grep(coin, colnames(input.data)), grep("bid_size", colnames(input.data)))
col.selection <- unique(c(col.selection, col.2))
}
library("readr")
library("quantmod")
library("forecast")
library("h2o")
library("dplyr")
library("TTR")
library("keras")
library("h2o")
library("caret")
library("jsonlite")
# Load the appropriate functions
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/parser.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/piecewise_correlation.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/support_functions.R")
full.dataset <- parser2("/Users/aaronpickering/Desktop/miscellaneous/momentum/datasets/momentum_dataset_1_20171125000000_20180122235900.txt", sample.split = 1)
# Extract all coins
all.coins <- unique(unlist(lapply(colnames(full.dataset), function(x){
x <- strsplit(x,"\\.\\.")[[1]][1]
if (!(x %in% c("date","time"))){
return(x)
} else {
return(NULL)
}
})))
# Set input data and output directory
input.data <- full.dataset
output.dir <- "/Users/aaronpickering/Desktop/miscellaneous/momentum/alternate/"
# filter dataset for Coin prefix and all the midprice suffixes
coin.specific.variables <- grep(coin, colnames(input.data))
coin.pairs <- grep("midprice", colnames(input.data))
if (use.bids.as.predictor == FALSE){
col.selection <- unique(c(coin.specific.variables, coin.pairs))
} else {
col.selection <- unique(c(coin.specific.variables, coin.pairs))
col.2 <- intersect(grep(coin, colnames(input.data)), grep("bid_size", colnames(input.data)))
col.selection <- unique(c(col.selection, col.2))
}
col.selection <- c("date","time",colnames(input.data)[col.selection])
dat <- input.data[,col.selection]
dat
colnames(dat)
rm(input.data)
colnames(dat)
colnames(dat) <- gsub("\\.\\.","__", colnames(dat))
dat <- as.data.frame(dat)
# Convert appropriate variables to numeric
factor.variables <- c("date","time")
# Convert variables to numeric, then normalise between 0 and 1 so that all time series are on the same plane
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.character)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.numeric)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, standardize)
# Create a dummy variable for every 10 minutes
dat$minute <- unlist(lapply(strsplit(as.character(dat$time), ":"), FUN=function(x){x[2]}))
# Even 10 minutes intervals for the prediction (10 minutes ahead)
dat <- subset(dat, dat$minute %in% c("00","10","20","30","40","50","60"))
# Make the other coins stationary, lag and apply the PCA
coin.pairs <- grep("midprice", colnames(dat))
coin.pairs
other.coins <- dat[,coin.pairs]
other.coins
dat[,!coin.pairs]
coin.pairs
dat[,!(1:ncol(dat) %in% coin.pairs)]
dat[,!(1:ncol(dat) %in% coin.pairs)]
# remove the other coin pairs from the original series
dat <- dat[,!(1:ncol(dat) %in% coin.pairs)]
other.coins
## make all the other  coin pairs stationary
for (j in 1:ncol(other,coins)){
print(j)
for (i in 1:nrow(other.coins)){
other.coins[i,j] <- other.coins[i,j]/other.coins[i-1,j]
}
}
## make all the other  coin pairs stationary
for (j in 1:ncol(other.coins)){
print(j)
for (i in 1:nrow(other.coins)){
other.coins[i,j] <- other.coins[i,j]/other.coins[i-1,j]
}
}
other.coins
## make all the other  coin pairs stationary
for (j in 1:ncol(other.coins)){
print(j)
for (i in 2:nrow(other.coins)){
other.coins[i,j] <- other.coins[i,j]/other.coins[i-1,j]
}
}
num.originals <- ncol(other.coins)
# apply lags to the coins
for (j in 1:num.originals){
# Add lags between 1 and 10
for (i in 1:10){
other.coins <- cbind(other.coins, Lag(other.coins[,j], i))
# Rename the newly added columns
colnames(other.coins)[ncol(other.coins)] <- paste(colnames(other.coins)[j], "::Lag_",i, sep="")
}
}
ncol(other.coins)
colnames(other.coins)
# Remove non lagged variables
other.coins <- other.coins[,(num.original + 1):ncol(other.coins)]
# Remove non lagged variables
other.coins <- other.coins[,(num.originals + 1):ncol(other.coins)]
colnames(other.coins)
library("readr")
library("quantmod")
library("forecast")
library("h2o")
library("dplyr")
library("TTR")
library("keras")
library("h2o")
library("caret")
library("jsonlite")
# Load the appropriate functions
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/parser.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/piecewise_correlation.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/support_functions.R")
full.dataset <- parser2("/Users/aaronpickering/Desktop/miscellaneous/momentum/datasets/momentum_dataset_1_20171125000000_20180122235900.txt", sample.split = 1)
# Extract all coins
all.coins <- unique(unlist(lapply(colnames(full.dataset), function(x){
x <- strsplit(x,"\\.\\.")[[1]][1]
if (!(x %in% c("date","time"))){
return(x)
} else {
return(NULL)
}
})))
# Set input data and output directory
input.data <- full.dataset
output.dir <- "/Users/aaronpickering/Desktop/miscellaneous/momentum/alternate/"
# filter dataset for Coin prefix and all the midprice suffixes
coin.specific.variables <- grep(coin, colnames(input.data))
coin
coin.pairs <- grep("midprice", colnames(input.data))
if (use.bids.as.predictor == FALSE){
col.selection <- unique(c(coin.specific.variables, coin.pairs))
} else {
col.selection <- unique(c(coin.specific.variables, coin.pairs))
col.2 <- intersect(grep(coin, colnames(input.data)), grep("bid_size", colnames(input.data)))
col.selection <- unique(c(col.selection, col.2))
}
col.selection <- c("date","time",colnames(input.data)[col.selection])
dat <- input.data[,col.selection]
rm(input.data)
colnames(dat)
colnames(dat) <- gsub("\\.\\.","__", colnames(dat))
dat <- as.data.frame(dat)
# Convert appropriate variables to numeric
factor.variables <- c("date","time")
# Convert variables to numeric, then normalise between 0 and 1 so that all time series are on the same plane
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.character)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.numeric)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, standardize)
# Create a dummy variable for every 10 minutes
dat$minute <- unlist(lapply(strsplit(as.character(dat$time), ":"), FUN=function(x){x[2]}))
# Even 10 minutes intervals for the prediction (10 minutes ahead)
dat <- subset(dat, dat$minute %in% c("00","10","20","30","40","50","60"))
# Make stationary
dependent.orig <- paste(coin,"__midprice",sep="")
dependent <- paste(coin,"__midprice.per",sep="")
plot(dat[,dependent.orig], type="lines")
dat[,dependent] <- NA
for (i in 2:nrow(dat)){
dat[i,dependent] <- dat[i,paste(coin,"__midprice", sep="")]/dat[i-1,paste(coin,"__midprice", sep="")]
}
# Log transform
dat[,dependent] <- log(dat[,dependent])
# Check stationarity
plot(dat[,dependent], type="lines")
# Make the other coins stationary, lag and apply the PCA
coin.pairs <- grep("midprice", colnames(dat))
other.coins <- dat[,coin.pairs]
# remove the other coin pairs from the original series
dat <- dat[,!(1:ncol(dat) %in% coin.pairs)]
## make all the other  coin pairs stationary
for (j in 1:ncol(other.coins)){
print(j)
for (i in 2:nrow(other.coins)){
other.coins[i,j] <- other.coins[i,j]/other.coins[i-1,j]
}
}
num.originals <- ncol(other.coins)
# apply lags to the coins
for (j in 1:num.originals){
# Add lags between 1 and 10
for (i in 1:10){
other.coins <- cbind(other.coins, Lag(other.coins[,j], i))
# Rename the newly added columns
colnames(other.coins)[ncol(other.coins)] <- paste(colnames(other.coins)[j], "::Lag_",i, sep="")
}
}
# Remove non lagged variables
other.coins <- other.coins[,(num.originals + 1):ncol(other.coins)]
principle.components <- prcomp(other.coins)
principle.components <- prcomp(na.omit(other.coins))
other.coins
na.omit(other.coins)
other.coins
library("readr")
library("quantmod")
library("forecast")
library("h2o")
library("dplyr")
library("TTR")
library("keras")
library("h2o")
library("caret")
library("jsonlite")
# Load the appropriate functions
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/parser.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/piecewise_correlation.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/support_functions.R")
full.dataset <- parser2("/Users/aaronpickering/Desktop/miscellaneous/momentum/datasets/momentum_dataset_1_20171125000000_20180122235900.txt", sample.split = 1)
# Extract all coins
all.coins <- unique(unlist(lapply(colnames(full.dataset), function(x){
x <- strsplit(x,"\\.\\.")[[1]][1]
if (!(x %in% c("date","time"))){
return(x)
} else {
return(NULL)
}
})))
# Set input data and output directory
input.data <- full.dataset
output.dir <- "/Users/aaronpickering/Desktop/miscellaneous/momentum/alternate/"
output.dir
# filter dataset for Coin prefix and all the midprice suffixes
coin.specific.variables <- grep(coin, colnames(input.data))
coin.pairs <- grep("midprice", colnames(input.data))
if (use.bids.as.predictor == FALSE){
col.selection <- unique(c(coin.specific.variables, coin.pairs))
} else {
col.selection <- unique(c(coin.specific.variables, coin.pairs))
col.2 <- intersect(grep(coin, colnames(input.data)), grep("bid_size", colnames(input.data)))
col.selection <- unique(c(col.selection, col.2))
}
col.selection <- c("date","time",colnames(input.data)[col.selection])
dat <- input.data[,col.selection]
head(dat)
dat <- as.data.frame(dat)
# Convert appropriate variables to numeric
factor.variables <- c("date","time")
# Convert variables to numeric, then normalise between 0 and 1 so that all time series are on the same plane
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.character)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.numeric)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, standardize)
# Create a dummy variable for every 10 minutes
dat$minute <- unlist(lapply(strsplit(as.character(dat$time), ":"), FUN=function(x){x[2]}))
# Even 10 minutes intervals for the prediction (10 minutes ahead)
dat <- subset(dat, dat$minute %in% c("00","10","20","30","40","50","60"))
# Make stationary
dependent.orig <- paste(coin,"__midprice",sep="")
dependent <- paste(coin,"__midprice.per",sep="")
plot(dat[,dependent.orig], type="lines")
dat[,dependent] <- NA
for (i in 2:nrow(dat)){
dat[i,dependent] <- dat[i,paste(coin,"__midprice", sep="")]/dat[i-1,paste(coin,"__midprice", sep="")]
}
# Log transform
dat[,dependent] <- log(dat[,dependent])
# Check stationarity
plot(dat[,dependent], type="lines")
head(dat)
# Convert appropriate variables to numeric
factor.variables <- c(paste(coin,"..update_date", sep=""),paste(coin,"..update_time", sep=""))
factor.variables
library("readr")
library("quantmod")
library("forecast")
library("h2o")
library("dplyr")
library("TTR")
library("keras")
library("h2o")
library("caret")
library("jsonlite")
# Load the appropriate functions
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/parser.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/piecewise_correlation.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/support_functions.R")
full.dataset <- parser2("/Users/aaronpickering/Desktop/miscellaneous/momentum/datasets/momentum_dataset_1_20171125000000_20180122235900.txt", sample.split = 1)
# Extract all coins
all.coins <- unique(unlist(lapply(colnames(full.dataset), function(x){
x <- strsplit(x,"\\.\\.")[[1]][1]
if (!(x %in% c("date","time"))){
return(x)
} else {
return(NULL)
}
})))
# Set input data and output directory
input.data <- full.dataset
output.dir <- "/Users/aaronpickering/Desktop/miscellaneous/momentum/alternate/"
# filter dataset for Coin prefix and all the midprice suffixes
coin.specific.variables <- grep(coin, colnames(input.data))
coin.pairs <- grep("midprice", colnames(input.data))
if (use.bids.as.predictor == FALSE){
col.selection <- unique(c(coin.specific.variables, coin.pairs))
} else {
col.selection <- unique(c(coin.specific.variables, coin.pairs))
col.2 <- intersect(grep(coin, colnames(input.data)), grep("bid_size", colnames(input.data)))
col.selection <- unique(c(col.selection, col.2))
}
col.selection <- c("date","time",colnames(input.data)[col.selection])
dat <- input.data[,col.selection]
rm(input.data)
colnames(dat)
colnames(dat) <- gsub("\\.\\.","__", colnames(dat))
dat <- as.data.frame(dat)
# Convert appropriate variables to numeric
factor.variables <- c(paste(coin,"..update_date", sep=""),paste(coin,"..update_time", sep=""))
# Convert variables to numeric, then normalise between 0 and 1 so that all time series are on the same plane
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.character)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.numeric)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, standardize)
# Create a dummy variable for every 10 minutes
dat$minute <- unlist(lapply(strsplit(as.character(dat$time), ":"), FUN=function(x){x[2]}))
head(dat)
library("readr")
library("quantmod")
library("forecast")
library("h2o")
library("dplyr")
library("TTR")
library("keras")
library("h2o")
library("caret")
library("jsonlite")
# Load the appropriate functions
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/parser.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/piecewise_correlation.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/support_functions.R")
full.dataset <- parser2("/Users/aaronpickering/Desktop/miscellaneous/momentum/datasets/momentum_dataset_1_20171125000000_20180122235900.txt", sample.split = 1)
# Extract all coins
all.coins <- unique(unlist(lapply(colnames(full.dataset), function(x){
x <- strsplit(x,"\\.\\.")[[1]][1]
if (!(x %in% c("date","time"))){
return(x)
} else {
return(NULL)
}
})))
# Set input data and output directory
input.data <- full.dataset
output.dir <- "/Users/aaronpickering/Desktop/miscellaneous/momentum/alternate/"
# filter dataset for Coin prefix and all the midprice suffixes
coin.specific.variables <- grep(coin, colnames(input.data))
coin.pairs <- grep("midprice", colnames(input.data))
if (use.bids.as.predictor == FALSE){
col.selection <- unique(c(coin.specific.variables, coin.pairs))
} else {
col.selection <- unique(c(coin.specific.variables, coin.pairs))
col.2 <- intersect(grep(coin, colnames(input.data)), grep("bid_size", colnames(input.data)))
col.selection <- unique(c(col.selection, col.2))
}
col.selection <- c("date","time",colnames(input.data)[col.selection])
dat <- input.data[,col.selection]
rm(input.data)
colnames(dat)
colnames(dat) <- gsub("\\.\\.","__", colnames(dat))
dat <- as.data.frame(dat)
# Convert appropriate variables to numeric
factor.variables <- c(paste(coin,"..update_date", sep=""),paste(coin,"..update_time", sep=""),"date","time")
factor.variables
colnames(dat)
# Convert appropriate variables to numeric
factor.variables <- c(paste(coin,"__update_date", sep=""),paste(coin,"__update_time", sep=""),"date","time")
# Convert variables to numeric, then normalise between 0 and 1 so that all time series are on the same plane
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.character)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, as.numeric)
dat[,!(colnames(dat) %in% factor.variables)] <- apply(dat[,!(colnames(dat) %in% factor.variables)], 2, standardize)
head(dat)
# Create a dummy variable for every 10 minutes
dat$minute <- unlist(lapply(strsplit(as.character(dat[]), ":"), FUN=function(x){x[2]}))
head(dat)
# Create a dummy variable for every 10 minutes
dat$minute <- unlist(lapply(strsplit(as.character(dat[,'time']), ":"), FUN=function(x){x[2]}))
head(dat)
# Even 10 minutes intervals for the prediction (10 minutes ahead)
dat <- subset(dat, dat$minute %in% c("00","10","20","30","40","50","60"))
# Make stationary
dependent.orig <- paste(coin,"__midprice",sep="")
dependent <- paste(coin,"__midprice.per",sep="")
plot(dat[,dependent.orig], type="lines")
dat[,dependent] <- NA
for (i in 2:nrow(dat)){
dat[i,dependent] <- dat[i,paste(coin,"__midprice", sep="")]/dat[i-1,paste(coin,"__midprice", sep="")]
}
# Log transform
dat[,dependent] <- log(dat[,dependent])
# Check stationarity
plot(dat[,dependent], type="lines")
# Make the other coins stationary, lag and apply the PCA
coin.pairs <- grep("midprice", colnames(dat))
other.coins <- dat[,coin.pairs]
# remove the other coin pairs from the original series
dat <- dat[,!(1:ncol(dat) %in% coin.pairs)]
other.coins
## make all the other  coin pairs stationary
for (j in 1:ncol(other.coins)){
print(j)
for (i in 2:nrow(other.coins)){
other.coins[i,j] <- other.coins[i,j]/other.coins[i-1,j]
}
}
num.originals <- ncol(other.coins)
# apply lags to the coins
for (j in 1:num.originals){
# Add lags between 1 and 10
for (i in 1:10){
other.coins <- cbind(other.coins, Lag(other.coins[,j], i))
# Rename the newly added columns
colnames(other.coins)[ncol(other.coins)] <- paste(colnames(other.coins)[j], "::Lag_",i, sep="")
}
}
# Remove non lagged variables
other.coins <- other.coins[,(num.originals + 1):ncol(other.coins)]
other.coins
principle.components <- prcomp(other.coins)
principle.components <- prcomp(na.omit(other.coins))
other.coins
na.omit(other.coins)
nrow(other.coins)
other.coins$`C5368__midprice::Lag_2`
other.coins$`C5368__midprice::Lag_3`
other.coins$`C5368__midprice::Lag_4`
other.coins$`C5368__midprice::Lag_4`
head(other.coins, 50)
head(other.coins[11,]
other.coins[11,]
colnames(other.coins)
# Remove the predicted coin
other.coins <- other.coins[,1:300]
na.omit(other.coins)
principle.components <- prcomp(na.omit(other.coins))
std.dev <- principle.components$sdev
std.dev
pr.var <- std.dev^2
proportion.var <- pr.var / sum(pr.var)
plot(cumsum(proportion.var), type="b")
cumsum(proportion.var)
# Select the first N components (9 components explain 99% of the variation as per the plot)
other.pca <- predict(principle.components, newdata=other.coins)[,1:9]
other.pca
plot(other.pca[,1])
plot(other.pca[,1], type="lines")
principle.components
predict(principle.components)
# Select the first N components (9 components explain 99% of the variation as per the plot)
other.pca <- predict(principle.components)[,1:9]
other.pca
plot(as.numeric(as.character(other.pca[,1])))
plot(as.numeric(as.character(other.pca[,2])))
plot(as.numeric(as.character(other.pca[,3])))
plot(as.numeric(as.character(other.pca[,4])))
plot(as.numeric(as.character(other.pca[,6])))
plot(as.numeric(as.character(other.pca[,7])))
# Select the first N components (9 components explain 99% of the variation as per the plot)
other.coins <- predict(principle.components)[,1:9]
# Start with lags of itself to 10 periods prior
for (l in 1:10){
lagged.var <- Lag(dat[,dependent], l)
dat <- cbind(dat, lagged.var)
colnames(dat)[ncol(dat)] <- paste(dependent,"::Lag_",l, sep="")
}
head(dat)
dependent
library("readr")
library("quantmod")
library("forecast")
library("h2o")
library("dplyr")
library("TTR")
library("keras")
library("h2o")
library("caret")
library("jsonlite")
# Load the appropriate functions
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/parser.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/piecewise_correlation.R")
source("/Users/aaronpickering/Desktop/miscellaneous/momentum/support_functions.R")
full.dataset <- parser2("/Users/aaronpickering/Desktop/miscellaneous/momentum/datasets/momentum_dataset_1_20171125000000_20180122235900.txt", sample.split = 1)
# Extract all coins
all.coins <- unique(unlist(lapply(colnames(full.dataset), function(x){
x <- strsplit(x,"\\.\\.")[[1]][1]
if (!(x %in% c("date","time"))){
return(x)
} else {
return(NULL)
}
})))
# Set input data and output directory
input.data <- full.dataset
output.dir <- "/Users/aaronpickering/Desktop/miscellaneous/momentum/alternate/"
